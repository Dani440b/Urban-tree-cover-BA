{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ded6043-a3ad-4ad2-82e4-2efa69d8aa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2ee11bf-f1b4-4eab-83f8-ea76fdd0e5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset._collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f562b013-c904-453c-aed4-0eb0400abfbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdataset\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataset\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_collate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m default_collate_with_shapely_support\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataset\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_image_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_images_table\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataset\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_data_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_same_crs\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataset\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_osm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_osm_geometries\n",
      "File \u001b[0;32m~/Documents/Bachelor-project/SAM-testing/dataset/_image_table.py:16\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save, load\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataset\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_data_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_same_crs\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform_to_crs\u001b[39m(project_crs\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEPSG:4326\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "from typing import Union, Optional, Tuple\n",
    "import logging\n",
    "import math\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "from itertools import product\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "from shapely.geometry import box\n",
    "from shapely.ops import transform, unary_union\n",
    "import pyproj\n",
    "from pyproj import Transformer\n",
    "import rasterio.features\n",
    "from rasterio import windows\n",
    "from rasterio.windows import Window\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Subset, Dataset, DataLoader\n",
    "import lightning.pytorch as pl\n",
    "from skimage.morphology import disk, dilation\n",
    "import fiona\n",
    "import dataset\n",
    "from dataset._collate import default_collate_with_shapely_support\n",
    "from dataset._image_table import build_images_table\n",
    "from dataset._data_utils import is_same_crs\n",
    "from dataset._osm import get_osm_geometries\n",
    "from dataset._data_utils import get_complete_areas, write_area_split, assign_target_polygons_to_areas\n",
    "from dataset._image_extractor import extract_images\n",
    "from utils.utils import set_abs_path\n",
    "\n",
    "class BaseDataset(Dataset):\n",
    "    \"\"\"\n",
    "    RemoteSensingDataset is designed to handle multiple sources of images at once.\n",
    "    These sources may have different resolutions, channels or CRS.\n",
    "    And the dataset would return a sample image accordingly. However, this flexibility has some limitations.\n",
    "    For example, the expected size in different resolution maybe a couple of bit off,\n",
    "    (assuming that they perfectly overlap).\n",
    "    More likely, a sample may lie across multiple tiles in some sources,\n",
    "    for that matter mapping each point on earth is still a very challenging task and it has its limitations.\n",
    "    While we find work around these limitations, it may not be possible always.\n",
    "\n",
    "    Note, that all the shape of patch, aoi and stride are given specific to a reference image source\n",
    "    (assuming there are multiple crs), and rest are of the shapes are sizes are calculated proportionally.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_name: str = 'train',\n",
    "        labeled_areas: gpd.GeoDataFrame=None,\n",
    "        images_df: gpd.GeoDataFrame=None,\n",
    "        assigned_target_features: gpd.GeoDataFrame=None,\n",
    "        assigned_nontrees_features: gpd.GeoDataFrame=None,\n",
    "        reference_source:str=None,\n",
    "        patch_size: Union[int, Tuple]=256,\n",
    "        allow_partial_patches: bool=False,\n",
    "        sequential_stride: Union[int, Tuple] = (256, 256),\n",
    "        dataset_transform=None,\n",
    "        processed_dir: str = None,\n",
    "        save_samples: bool = False,\n",
    "        save_patch_df: bool = False,\n",
    "        save_labeled_areas_df: bool = False,\n",
    "        extract_images_for_areas: bool=False,\n",
    "        project_crs: str = None,\n",
    "        merge_mode: str = \"keep_first\",\n",
    "        extracted_image_col:str='extracted_images',\n",
    "        get_patch_custom: callable=None,\n",
    "    ) -> None:\n",
    "        super(Dataset, self).__init__()\n",
    "        assert patch_size is not None\n",
    "        if type(patch_size) == int:\n",
    "            patch_size = (patch_size, patch_size)\n",
    "            \n",
    "        assert sequential_stride is not None\n",
    "        if type(sequential_stride) == int:\n",
    "            sequential_stride = (sequential_stride, sequential_stride)\n",
    "            \n",
    "        self.dataset_name = dataset_name\n",
    "        self.images_df = images_df\n",
    "        self.assigned_target_features = assigned_target_features\n",
    "        self.assigned_nontrees_features = assigned_nontrees_features\n",
    "        self.dataset_transform = dataset_transform\n",
    "        self.extract_images_for_areas = extract_images_for_areas\n",
    "        self.reference_source = reference_source\n",
    "        self.processed_dir = processed_dir\n",
    "        self.save_samples = save_samples\n",
    "        self.project_crs = project_crs\n",
    "        self.merge_mode = merge_mode\n",
    "        self.patch_size = patch_size\n",
    "        self.get_patch_custom = get_patch_custom\n",
    "\n",
    "        if labeled_areas.empty:\n",
    "            return\n",
    "            \n",
    "        if self.processed_dir:\n",
    "            logging.info(f\"Processed_dir path: {self.processed_dir}\")\n",
    "            self.processed_dir = Path(self.processed_dir)\n",
    "            # create processed sample dir\n",
    "            self.processed_dir.mkdir(exist_ok=True)\n",
    "            patch_df_path = self.processed_dir / f\"{dataset_name}_patch_df.pt\"\n",
    "            labeled_areas_df_path = self.processed_dir / f\"{dataset_name}_labeled_areas_df.pt\"\n",
    "\n",
    "\n",
    "        if (self.save_samples or save_patch_df or save_labeled_areas_df) and not self.processed_dir:\n",
    "            raise Exception(\"No 'processed_dir' provided, cannot save samples or patch_df or save_labeled_areas_df.\")\n",
    "        elif not (self.save_samples or save_patch_df or save_labeled_areas_df) and self.processed_dir:\n",
    "            warnings.warn(\"You provided 'processed_dir' provided but neither samples nor patch_df are saved.\")\n",
    "        elif self.processed_dir:\n",
    "            (self.processed_dir / 'patches').mkdir(exist_ok=True)\n",
    "            logging.info(f\"Saving samples:{self.save_samples}, patch_df: {save_patch_df} to {self.processed_dir}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # For backward compatibility; it can be removed once it has been run for all training scripts.\n",
    "        if self.processed_dir and save_labeled_areas_df and save_patch_df and patch_df_path.exists():\n",
    "            extract_labeled_areas_from_patch_dict(patch_df_path, labeled_areas_df_path)\n",
    "\n",
    "        if self.processed_dir and save_labeled_areas_df and labeled_areas_df_path.exists():\n",
    "            logging.info(f\"Reading labeled areas from {labeled_areas_df_path}\")\n",
    "            lb_dict = torch.load(labeled_areas_df_path)\n",
    "            self.labeled_areas = lb_dict[\"labeled_areas\"]\n",
    "            self.assigned_images = lb_dict[\"assigned_images\"]\n",
    "            logging.info(f\"Done reading labeled areas\")\n",
    "        else:\n",
    "            logging.info(f\"Creating labeled areas and assigned images for dataset {self.dataset_name}\")\n",
    "            self.labeled_areas, self.assigned_images = self.build_labeled_areas_table(labeled_areas.copy(), extract_images_for_areas, extracted_image_col)\n",
    "            if self.processed_dir and save_labeled_areas_df:\n",
    "                lb_dict = {\n",
    "                    \"labeled_areas\": self.labeled_areas,\n",
    "                    \"assigned_images\": self.assigned_images,\n",
    "                }\n",
    "                torch.save(lb_dict, labeled_areas_df_path)\n",
    "\n",
    "        if self.processed_dir and save_patch_df and patch_df_path.exists():\n",
    "            patch_dict = torch.load(patch_df_path)\n",
    "            self.patch_df = patch_dict[\"patch_df\"]\n",
    "            self.length = len(self.patch_df)\n",
    "        else:\n",
    "            self.patch_df, self.length = self.build_patch_table_sequentially(sequential_stride=sequential_stride, allow_partial_patches=allow_partial_patches)\n",
    "            if self.processed_dir and save_patch_df:\n",
    "                patch_dict = {\"patch_df\": self.patch_df}\n",
    "                torch.save(patch_dict, patch_df_path)\n",
    "\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.processed_dir and self.save_samples:\n",
    "            path = self.processed_dir / 'patches' / f\"{self.dataset_name}_{idx}.pt\"\n",
    "            if path.exists():\n",
    "                try:\n",
    "                    sample = torch.load(path)\n",
    "                except Exception as e:\n",
    "                    logging.info(e)\n",
    "                    sample = self.get_patch(idx)\n",
    "                    torch.save(sample, path)\n",
    "            else:\n",
    "                sample = self.get_patch(idx)\n",
    "                torch.save(sample, path)\n",
    "        else:\n",
    "            sample = self.get_patch(idx)\n",
    "        if self.dataset_transform:\n",
    "            sample = self.dataset_transform(sample)\n",
    "        return sample\n",
    "\n",
    "    \n",
    "    def get_patch(self, idx: int):\n",
    "        # Should returns a dict per source\n",
    "        patch = self.patch_df.loc[idx]\n",
    "        pt = patch.to_dict()\n",
    "        pt.update(self.get_patch_raster_images(patch))\n",
    "        pt['patch_id'] = idx\n",
    "\n",
    "        if self.get_patch_custom:\n",
    "            pt = self.get_patch_custom(pt=pt, dataset_name=self.dataset_name,labeled_areas=self.labeled_areas)\n",
    "        \n",
    "        return pt\n",
    "    \n",
    "    def get_patch_raster_images(self, patch):\n",
    "        pt = {}\n",
    "        overlapping_images = self.get_patch_overlapping_images(patch)\n",
    "        # Handle different source by defining window using bounds\n",
    "        # While it's nice to have overlapping images in the patch sample, it creates problems in dataloader collate.\n",
    "        # pt['overlapping_images'] = overlapping_images.index.tolist()\n",
    "        for _, img in overlapping_images.iterrows():\n",
    "            src_name = img[\"src\"]\n",
    "            # transform to reference image crs\n",
    "            patch_geom = patch.geometry\n",
    "            wn_geom = geometry_to_crs(patch_geom, self.project_crs, img[\"ori_crs\"])\n",
    "            # careful here, the windows is from the bounds not the geometry of the patch\n",
    "            wn = rasterio.windows.from_bounds(*wn_geom.bounds, transform=img['ori_transform'])\n",
    "            # This is required due to a rounding error while creating the window and case when the window is less than 1 pixel\n",
    "            wn = Window(np.floor(wn.col_off), np.floor(wn.row_off), max(1, round(wn.width)), max(1, round(wn.height)))\n",
    "\n",
    "            img_arr = self.read_window_from_image(img_path=img[\"path\"], wn=wn, boundless=True)\n",
    "            # need to reproject if different reference crs was used\n",
    "            img_arr = img_arr.astype(np.float32)\n",
    "            nan_mask = np.isnan(img_arr) | (img_arr == img[\"nodatavals\"])  # | (img_arr == 0)\n",
    "            img_arr[nan_mask] = np.nan\n",
    "            if src_name in pt:\n",
    "                if self.merge_mode == \"keep_first\":\n",
    "                    nan_mask = np.isnan(pt[src_name])\n",
    "                    pt[src_name] = np.where(nan_mask, img_arr, pt[src_name])\n",
    "                if self.merge_mode == 'keep_last':\n",
    "                    pt[src_name] = np.where(nan_mask, pt[src_name], img_arr)\n",
    "            else:\n",
    "                pt[src_name] = img_arr\n",
    "        for src_name in overlapping_images[\"src\"].unique():\n",
    "            pt[src_name] = torch.tensor(pt[src_name], dtype=torch.float32)\n",
    "        return pt\n",
    "    \n",
    "    def get_patch_overlapping_images(self, patch):\n",
    "        ov_im = self.assigned_images.query(\"area_id == @patch.area_id\")\n",
    "        # For multiple sources, creates patches on the reference source and then select images that overlap the patch\n",
    "        overlapping_images = self.images_df.loc[ov_im.reset_index().image_id]\n",
    "        overlapping_images = overlapping_images[overlapping_images.intersects(patch.geometry)]\n",
    "        return overlapping_images\n",
    "\n",
    "    def build_labeled_areas_table(self, labeled_areas: gpd.GeoDataFrame, extract_images_for_areas=False, extracted_image_col = \"extracted_images\"):\n",
    "        \"\"\"\n",
    "        assign area id to each image\n",
    "        Sample table:\n",
    "        area_id, geometry, area_size_pixel ,polygons, patch_start_index, patch_end_index, overlapping_images\n",
    "        1,  [[1,2], [300,400]], (5000,5000), [[[1,2], [5,6], [64,3]], [[83,45], [34, 45], [97, 66]]], 0, 120, [img1.tif, img2.tif]\n",
    "        \"\"\"\n",
    "\n",
    "        assigned_images = gpd.sjoin(self.images_df[[\"src\", \"geometry\"]],\n",
    "                                    labeled_areas[[\"geometry\"]],\n",
    "                                    predicate=\"intersects\",\n",
    "                                    how=\"inner\").rename(columns={\"index_right\": \"area_id\"})\n",
    "        # filter out not found values\n",
    "        missing_areas = labeled_areas.query(\"index not in @assigned_images.area_id\")\n",
    "        labeled_areas = labeled_areas.query(\"index in @assigned_images.area_id\")\n",
    "        if len(missing_areas) > 0:\n",
    "            logging.info(f\"{len(missing_areas)} areas with no image source, idx: {missing_areas.index}\")\n",
    "            logging.info(f\"ignoring them for now\")\n",
    "        complete_areas = assigned_images.query(\"src == @self.reference_source\").area_id\n",
    "        missing_areas = labeled_areas.query(\"index not in @complete_areas\")\n",
    "        labeled_areas = labeled_areas.query(\"index in @complete_areas\")\n",
    "        assigned_images = assigned_images.query(\"area_id in @complete_areas\")\n",
    "        if len(missing_areas) > 0:\n",
    "            logging.info(f\"{len(missing_areas)} areas with no input image source, idx: {missing_areas.index}\")\n",
    "            logging.info(f\"ignoring them for now\")\n",
    "        assigned_images.set_index(['area_id'], append=True, inplace=True)\n",
    "        assert assigned_images.index.names == [\"image_id\", \"area_id\"]\n",
    "        # assigned_images.set_index([\"area_id\", \"image_id\"], inplace=True)\n",
    "        # todo this is ugly but faster than apply on the outer loop\n",
    "        area_info = []\n",
    "        for area_id, group_df in assigned_images.groupby(\"area_id\"):\n",
    "            area_geom = labeled_areas.loc[area_id]['geometry']\n",
    "\n",
    "            def get_overlapping_area(row):\n",
    "                # These transform represent the overlapping transform, shape and geometry so renamed it to ov from area\n",
    "                return pd.Series([area_geom.intersection(row['geometry'])], index=[\"ov_geometry\"])\n",
    "\n",
    "            overlapping_area = group_df.apply(get_overlapping_area, axis=1)\n",
    "            area_info.append((overlapping_area))\n",
    "\n",
    "        area_info = pd.concat(area_info, axis=0)\n",
    "        # add to lookup table\n",
    "        assigned_images = assigned_images.join(area_info)\n",
    "        # Geometry and transform refer to the geometry of the original image instead of its overlap with the rectangle.\n",
    "        # So we delete these columns and replace them with the common area-image transform and geometry\n",
    "        assigned_images.set_geometry('ov_geometry', inplace=True)\n",
    "        assigned_images.drop(labels=['geometry'], axis=\"columns\", inplace=True)\n",
    "        assigned_images.rename_geometry('geometry', inplace=True)\n",
    "\n",
    "        if extract_images_for_areas and self.processed_dir is not None:\n",
    "            ep = self.processed_dir / 'extracted_images'\n",
    "            if ep.exists() and ep.iterdir():\n",
    "                raise Exception(\n",
    "                    f\"Extracted images already exist in {ep}!!\" + f\"\\nPlease remove the folder to re-extract.\" +\n",
    "                    f\"\\nOtherwise change image source to the extracted location and set image extract to False\")\n",
    "            else:\n",
    "                ep.mkdir(exist_ok=True)\n",
    "                logging.info(f\"Extracting relevant image parts to {ep}\")\n",
    "                assigned_images = extract_images(areas=labeled_areas,\n",
    "                                                 images_df=self.images_df,\n",
    "                                                 base_dir=ep,\n",
    "                                                 extracted_image_col=extracted_image_col,\n",
    "                                                 assigned_images=assigned_images,\n",
    "                                                 prefix=self.dataset_name)\n",
    "                assert extracted_image_col in assigned_images.columns\n",
    "        else:\n",
    "            logging.info(\"Not extracting images.\")\n",
    "\n",
    "        return labeled_areas, assigned_images\n",
    "\n",
    "\n",
    "    def build_patch_table_sequentially(self, patch_start_index=0, sequential_stride=1, allow_partial_patches=False):\n",
    "        patches = []\n",
    "        height, width = self.patch_size\n",
    "        images_grouped_by_area = self.assigned_images.query(f\"src == '{self.reference_source}'\").groupby('area_id')\n",
    "        for area_idx, area_images in tqdm(images_grouped_by_area, desc=\"Iterating over areas\"):\n",
    "            area = self.labeled_areas.loc[area_idx]  # Returns a series\n",
    "            img_indices = area_images.reset_index()[\"image_id\"].values\n",
    "            imgs = self.images_df.loc[img_indices]  #TODO:assign self.images_df\n",
    "\n",
    "            ori_crs, ori_transform, union_geometry = get_imgs_reference(imgs)\n",
    "            # TODO: Verify!\n",
    "            # We still want to work with the overlapping geometry instead of the pure image geometry\n",
    "            union_geometry = union_geometry.intersection(area.geometry)\n",
    "\n",
    "            # Now we divide this geometry into smaller patches\n",
    "            # Use the point approach; start with the top left point,\n",
    "            # get positions in image space\n",
    "            col_start, col_end, row_start, row_end = self.get_rows_cols_from_geom(ori_crs, ori_transform,\n",
    "                                                                                  union_geometry)\n",
    "\n",
    "            if row_start > row_end or col_start > col_end:\n",
    "                logging.info(f\"row_start > row_end or col_start > col_end {row_start} {row_end} {col_start} {col_end}\")\n",
    "\n",
    "            stride_row, stride_col = sequential_stride\n",
    "            if allow_partial_patches:\n",
    "                col_itr_start = col_start\n",
    "                row_itr_start = row_start\n",
    "                col_itr_end = col_end\n",
    "                row_itr_end = row_end\n",
    "            else:\n",
    "                # use center\n",
    "                col_itr_start = col_start + ((col_end - col_start) % height) // 2\n",
    "                row_itr_start = row_start + ((row_end - row_start) % width) // 2\n",
    "                col_itr_end = col_end - height\n",
    "                row_itr_end = row_end - width\n",
    "\n",
    "            for col, row in product(range(col_itr_start, col_itr_end, stride_col),\n",
    "                                    range(row_itr_start, row_itr_end, stride_row)):\n",
    "                # Window is defined as offset in pure image space\n",
    "                wn = Window(col, row, width, height)\n",
    "                wx, wy = rasterio.transform.xy(ori_transform, [row, row + width], [col, col + height])\n",
    "                # Window box in original CRS\n",
    "                wn_geometry = box(wx[0], wy[1], wx[1], wy[0])  # left, bottom, right, top\n",
    "                transform_in_ori_crs = windows.transform(wn, ori_transform)\n",
    "\n",
    "                patch = {\n",
    "                    \"ori_geometry\": wn_geometry,\n",
    "                    \"geometry\": wn_geometry,  # !!This is a placeholder which is transformed to project_crs in the end\n",
    "                    \"shape\": (height, width),\n",
    "                    \"wn_ori\": (col, row, width, height),\n",
    "                    \"ori_crs\": ori_crs,\n",
    "                    \"ori_transform\": transform_in_ori_crs,\n",
    "                    \"area_id\": area_idx,\n",
    "                }\n",
    "\n",
    "                patches.append(patch)\n",
    "\n",
    "        pdf = gpd.GeoDataFrame.from_dict(patches).set_crs(self.project_crs)\n",
    "        pdf = get_df_in_single_crs(pdf, self.project_crs)\n",
    "\n",
    "        # REMOVE ALL-0 MASKED PATCHES\n",
    "        def features_count(rw, atf=self.assigned_target_features,nontf=self.assigned_nontrees_features):\n",
    "            trfs = len(get_patch_features(atf, rw.geometry, area_id=rw.area_id))\n",
    "            nontf = len(get_patch_features(nontf, rw.geometry, area_id=rw.area_id))\n",
    "            return trfs + nontf\n",
    "\n",
    "        # if not (self.allow_empty_patches or self.target_features is None):  # 2. Case of prediction\n",
    "        pdf['n_features'] = pdf.apply(features_count, axis=1) \n",
    "        pdf = pdf.query(\"n_features > 0\") # to remove all-0 masked patches, there're no target features neither non-target features\n",
    "\n",
    "        pdf['patch_id'] = range(patch_start_index, len(pdf) + patch_start_index)\n",
    "\n",
    "        # verify that patches overlap with labeled_area they come from and adhere to their shape\n",
    "        pdfs = []\n",
    "        for area_idx in self.labeled_areas.index:\n",
    "            pdfs.append(\n",
    "                pdf.query(\"area_id == @area_idx\").sjoin(self.labeled_areas.query(\"index == @area_idx\"),\n",
    "                                                        how=\"inner\",\n",
    "                                                        predicate=\"intersects\",\n",
    "                                                        lsuffix=\"\")[pdf.columns])\n",
    "        pdf = pd.concat(pdfs)\n",
    "        pdf.drop_duplicates(\"patch_id\", inplace=True)\n",
    "\n",
    "        pdf['patch_id'] = range(patch_start_index, len(pdf) + patch_start_index)\n",
    "\n",
    "        pdf.set_index(\"patch_id\", inplace=True)\n",
    "\n",
    "        if self.processed_dir is not None:\n",
    "            p = self.processed_dir / 'qgis' / self.dataset_name\n",
    "            logging.info(f\"Writing labeled areas, image df and assigned images to {p}\")\n",
    "            p.mkdir(exist_ok=True, parents=True)\n",
    "            with fiona.Env(OSR_WKT_FORMAT=\"WKT2_2018\"):\n",
    "                pdf[['geometry', 'area_id']].to_file(p / \"patch_grid.gpkg\", driver=\"GPKG\")\n",
    "                self.labeled_areas[['geometry']].to_file(p / \"labeled_areas.gpkg\", driver=\"GPKG\")\n",
    "                self.images_df[['geometry', 'path']].to_file(p / \"image_df.gpkg\", driver=\"GPKG\")\n",
    "                self.assigned_images[['geometry']].to_file(p / \"assigned_images.gpkg\", driver=\"GPKG\")\n",
    "                if self.assigned_target_features is not None:\n",
    "                    self.assigned_target_features[['geometry']].to_file(p / \"assigned_target_features.gpkg\", driver=\"GPKG\")\n",
    "\n",
    "        return pdf, len(pdf)\n",
    "    \n",
    "    def get_rows_cols_from_geom(self, target_crs, ori_transform, geometry):\n",
    "        minx, miny, maxx, maxy = geometry.bounds\n",
    "        transformer_to_ori = Transformer.from_crs(self.project_crs, target_crs, always_xy=True)\n",
    "        # Get the points in image coordinate reference system\n",
    "        ic_minx, ic_maxy = transformer_to_ori.transform(minx, maxy)  # Top left\n",
    "        ic_maxx, ic_miny = transformer_to_ori.transform(maxx, miny)  # Bottom right\n",
    "        # In a normal array, row, col (0,0) means top left and row increase downwards\n",
    "        #   while the column increase right wards\n",
    "        # In a geo reference image with xy (longitude, latitude) orientation,\n",
    "        #   y decreases south wards (opposite of rows) and x increases east wards (same as columns)\n",
    "        row_start, col_start = rasterio.transform.rowcol(ori_transform, ic_minx,\n",
    "                                                         ic_maxy)  # Bottom left, i.e image start\n",
    "        row_end, col_end = rasterio.transform.rowcol(ori_transform, ic_maxx, ic_miny)  # Top right, i.e image end\n",
    "        return col_start, col_end, row_start, row_end\n",
    "\n",
    "    @staticmethod\n",
    "    def read_window_from_image(img_path, wn, boundless=True, fill_value=0):\n",
    "        with rasterio.open(img_path) as src:\n",
    "            rw = src.read(window=wn, boundless=boundless, fill_value=fill_value)\n",
    "        return rw\n",
    "\n",
    "    @staticmethod\n",
    "    def save(dataset, path):\n",
    "        if not str(path).endswith('.pt'):\n",
    "            path = path / f'dataset.pt'\n",
    "        try:\n",
    "            torch.save(dataset, path)\n",
    "            return 1\n",
    "        except Exception as e:\n",
    "            return 0\n",
    "\n",
    "    @staticmethod\n",
    "    def load(path):\n",
    "        if not str(path).endswith('.pt'):\n",
    "            path = path / f'dataset.pt'\n",
    "        return torch.load(path)\n",
    "\n",
    "    @staticmethod\n",
    "    def patches_count_calculator(area_dim, patch_dim, stride_dim, first_partial_patch=True):\n",
    "        n = ((area_dim - patch_dim) / stride_dim) + 1\n",
    "        if first_partial_patch:\n",
    "            return max(1, math.ceil(n))\n",
    "        else:\n",
    "            return max(0, math.floor(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb509541-877f-4771-9bab-255d68a1d053",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
